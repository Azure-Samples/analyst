{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Responses:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-BHyFVZ0HEapnlNrInOBU79yVTWxKb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Below is a complete response outlining both the analysis strategy and the final code solution.\\n\\n──────────────────────────────\\nAnalysis Strategy and Step-by-Step Reasoning\\n\\n1. Data Ingestion:\\n   • We load the CSV data into a pandas DataFrame.\\n   • We assume the CSV is complete (no missing values) and all columns are numeric.\\n\\n2. Initial Data Exploration:\\n   • Use df.head() to inspect the first few rows.\\n   • Use df.describe() to obtain summary statistics (mean, std, min, quartiles, and max) for each variable.\\n\\n3. Identifying Patterns:\\n   • Notice that “feature” runs from 1 to 100.\\n   • “target” appears to be exactly twice “feature” (i.e. target = 2 * feature).\\n   • “col3” is 10 units more than feature (i.e. col3 = feature + 10).\\n   • “col4” is half of feature (i.e. col4 = feature * 0.5).\\n   • A quick correlation check using df.corr() will confirm these strong linear relationships.\\n\\n4. Data Visualization:\\n   • Use scatter plots or a pairplot (via seaborn) to visualize pairwise relationships.\\n   • Plot “feature” versus “target” along with the regression line to confirm the linear relationship.\\n   • Similarly, plot “feature” against “col3” and “col4” to visually verify the patterns.\\n\\n5. Regression Analysis:\\n   • Fit a simple linear regression model to predict “target” as a function of “feature”.\\n   • Print the regression coefficient and intercept to confirm the relation (expected slope ≈2, intercept ≈0).\\n\\n6. Assumptions:\\n   • The dataset is generated using simple linear equations.\\n   • There are no missing values or outliers that require special handling.\\n   • The relationships can be revealed using summary statistics, correlation analysis, scatter plots, and linear regression.\\n\\n──────────────────────────────\\nFinal Code Solution\\n\\nBelow is the code that implements the above strategy. This code reads the CSV data (provided as a multi‐line string for self-containment), performs the exploratory analysis and regression, and produces corresponding plots.\\n\\n──────────────────────────────\\n[Begin Code]\\n\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom io import StringIO\\nfrom sklearn.linear_model import LinearRegression\\n\\n# The CSV data provided by the user.\\ncsv_data = \"\"\"feature,target,col3,col4\\n1,2,11,0.5\\n2,4,12,1.0\\n3,6,13,1.5\\n4,8,14,2.0\\n5,10,15,2.5\\n6,12,16,3.0\\n7,14,17,3.5\\n8,16,18,4.0\\n9,18,19,4.5\\n10,20,20,5.0\\n11,22,21,5.5\\n12,24,22,6.0\\n13,26,23,6.5\\n14,28,24,7.0\\n15,30,25,7.5\\n16,32,26,8.0\\n17,34,27,8.5\\n18,36,28,9.0\\n19,38,29,9.5\\n20,40,30,10.0\\n21,42,31,10.5\\n22,44,32,11.0\\n23,46,33,11.5\\n24,48,34,12.0\\n25,50,35,12.5\\n26,52,36,13.0\\n27,54,37,13.5\\n28,56,38,14.0\\n29,58,39,14.5\\n30,60,40,15.0\\n31,62,41,15.5\\n32,64,42,16.0\\n33,66,43,16.5\\n34,68,44,17.0\\n35,70,45,17.5\\n36,72,46,18.0\\n37,74,47,18.5\\n38,76,48,19.0\\n39,78,49,19.5\\n40,80,50,20.0\\n41,82,51,20.5\\n42,84,52,21.0\\n43,86,53,21.5\\n44,88,54,22.0\\n45,90,55,22.5\\n46,92,56,23.0\\n47,94,57,23.5\\n48,96,58,24.0\\n49,98,59,24.5\\n50,100,60,25.0\\n51,102,61,25.5\\n52,104,62,26.0\\n53,106,63,26.5\\n54,108,64,27.0\\n55,110,65,27.5\\n56,112,66,28.0\\n57,114,67,28.5\\n58,116,68,29.0\\n59,118,69,29.5\\n60,120,70,30.0\\n61,122,71,30.5\\n62,124,72,31.0\\n63,126,73,31.5\\n64,128,74,32.0\\n65,130,75,32.5\\n66,132,76,33.0\\n67,134,77,33.5\\n68,136,78,34.0\\n69,138,79,34.5\\n70,140,80,35.0\\n71,142,81,35.5\\n72,144,82,36.0\\n73,146,83,36.5\\n74,148,84,37.0\\n75,150,85,37.5\\n76,152,86,38.0\\n77,154,87,38.5\\n78,156,88,39.0\\n79,158,89,39.5\\n80,160,90,40.0\\n81,162,91,40.5\\n82,164,92,41.0\\n83,166,93,41.5\\n84,168,94,42.0\\n85,170,95,42.5\\n86,172,96,43.0\\n87,174,97,43.5\\n88,176,98,44.0\\n89,178,99,44.5\\n90,180,100,45.0\\n91,182,101,45.5\\n92,184,102,46.0\\n93,186,103,46.5\\n94,188,104,47.0\\n95,190,105,47.5\\n96,192,106,48.0\\n97,194,107,48.5\\n98,196,108,49.0\\n99,198,109,49.5\\n100,200,110,50.0\"\"\"\\n\\n# Load the data into a DataFrame.\\ndf = pd.read_csv(StringIO(csv_data))\\n\\n# 1. Inspect the DataFrame\\nprint(\"First 5 rows of the dataset:\")\\nprint(df.head())\\n\\n# 2. Summary statistics for each column.\\nprint(\"\\\\nSummary Statistics:\")\\nprint(df.describe())\\n\\n# 3. Compute pairwise correlation matrix.\\nprint(\"\\\\nPairwise Correlation Matrix:\")\\nprint(df.corr())\\n\\n# 4. Visualize Pairwise Relationships with seaborn pairplot.\\nsns.pairplot(df)\\nplt.suptitle(\"Pairwise Relationships in the Dataset\", y=1.02)\\nplt.show()\\n\\n# 5. Detailed Scatter Plot and Regression Analysis:\\n# Scatter plot of \\'feature\\' vs. \\'target\\'\\nplt.figure(figsize=(8, 5))\\nsns.scatterplot(data=df, x=\\'feature\\', y=\\'target\\', color=\\'blue\\', s=60, label=\\'Data Points\\')\\n\\n# Fit a linear regression model to predict target from feature.\\nmodel = LinearRegression()\\nX = df[[\\'feature\\']]  # independent variable\\ny = df[\\'target\\']     # dependent variable\\nmodel.fit(X, y)\\n\\n# Retrieve the coefficient and intercept.\\nslope = model.coef_[0]\\nintercept = model.intercept_\\nprint(\"\\\\nLinear Regression Model for Target ~ Feature:\")\\nprint(f\"Slope (Coefficient): {slope}\")\\nprint(f\"Intercept: {intercept}\")\\n\\n# Generate predictions across the range of feature for the regression line.\\nX_range = pd.DataFrame({\\'feature\\': [df[\\'feature\\'].min(), df[\\'feature\\'].max()]})\\ny_pred = model.predict(X_range)\\n\\n# Plot regression line.\\nplt.plot(X_range[\\'feature\\'], y_pred, color=\\'red\\', lw=2, label=f\"Regression Line (y={slope:.2f}x+{intercept:.2f})\")\\nplt.xlabel(\\'Feature\\')\\nplt.ylabel(\\'Target\\')\\nplt.title(\\'Scatter Plot with Regression Line (Feature vs. Target)\\')\\nplt.legend()\\nplt.show()\\n\\n──────────────────────────────\\nExplanation\\n\\n• The code starts by reading the CSV data from the provided multi‐line string.\\n• It prints out the first few rows along with summary statistics using describe().\\n• Next, it computes and prints the correlation matrix to reveal very high correlations among columns (confirming the linear relationships).\\n• A pairplot is generated to visually inspect all pairwise relationships.\\n• A specific scatter plot of “feature” vs. “target” is produced with a red regression line overlaid.\\n• A simple linear regression is performed where we fit “feature” to “target”, and the printed slope and intercept confirm that target ≈ 2 × feature (with slope nearly 2 and an intercept near zero).\\n\\nRunning this code will provide a data-driven confirmation of the underlying linear patterns in the dataset.\\n\\n──────────────────────────────\\nExecution\\n\\nBelow is the execution of the provided Python code. (If running in an interactive environment, the plots will be displayed inline.)\\n\\n[End Code]\\n\\nThis approach is fully data-driven, aligns with the dataset’s structure, and clearly shows that the dataset’s columns are linearly related in the way described.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1743622873, model='o3-mini-2025-01-31', object='chat.completion', service_tier=None, system_fingerprint='fp_ded0d14823', usage=CompletionUsage(completion_tokens=3820, prompt_tokens=1116, total_tokens=4936, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1664, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]), ai_model_id='o3-mini', metadata={'logprobs': None, 'id': 'chatcmpl-BHyFVZ0HEapnlNrInOBU79yVTWxKb', 'created': 1743622873, 'system_fingerprint': 'fp_ded0d14823', 'usage': CompletionUsage(prompt_tokens=1116, completion_tokens=3820)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name='reasoning_agent', items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Below is a complete response outlining both the analysis strategy and the final code solution.\\n\\n──────────────────────────────\\nAnalysis Strategy and Step-by-Step Reasoning\\n\\n1. Data Ingestion:\\n   • We load the CSV data into a pandas DataFrame.\\n   • We assume the CSV is complete (no missing values) and all columns are numeric.\\n\\n2. Initial Data Exploration:\\n   • Use df.head() to inspect the first few rows.\\n   • Use df.describe() to obtain summary statistics (mean, std, min, quartiles, and max) for each variable.\\n\\n3. Identifying Patterns:\\n   • Notice that “feature” runs from 1 to 100.\\n   • “target” appears to be exactly twice “feature” (i.e. target = 2 * feature).\\n   • “col3” is 10 units more than feature (i.e. col3 = feature + 10).\\n   • “col4” is half of feature (i.e. col4 = feature * 0.5).\\n   • A quick correlation check using df.corr() will confirm these strong linear relationships.\\n\\n4. Data Visualization:\\n   • Use scatter plots or a pairplot (via seaborn) to visualize pairwise relationships.\\n   • Plot “feature” versus “target” along with the regression line to confirm the linear relationship.\\n   • Similarly, plot “feature” against “col3” and “col4” to visually verify the patterns.\\n\\n5. Regression Analysis:\\n   • Fit a simple linear regression model to predict “target” as a function of “feature”.\\n   • Print the regression coefficient and intercept to confirm the relation (expected slope ≈2, intercept ≈0).\\n\\n6. Assumptions:\\n   • The dataset is generated using simple linear equations.\\n   • There are no missing values or outliers that require special handling.\\n   • The relationships can be revealed using summary statistics, correlation analysis, scatter plots, and linear regression.\\n\\n──────────────────────────────\\nFinal Code Solution\\n\\nBelow is the code that implements the above strategy. This code reads the CSV data (provided as a multi‐line string for self-containment), performs the exploratory analysis and regression, and produces corresponding plots.\\n\\n──────────────────────────────\\n[Begin Code]\\n\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom io import StringIO\\nfrom sklearn.linear_model import LinearRegression\\n\\n# The CSV data provided by the user.\\ncsv_data = \"\"\"feature,target,col3,col4\\n1,2,11,0.5\\n2,4,12,1.0\\n3,6,13,1.5\\n4,8,14,2.0\\n5,10,15,2.5\\n6,12,16,3.0\\n7,14,17,3.5\\n8,16,18,4.0\\n9,18,19,4.5\\n10,20,20,5.0\\n11,22,21,5.5\\n12,24,22,6.0\\n13,26,23,6.5\\n14,28,24,7.0\\n15,30,25,7.5\\n16,32,26,8.0\\n17,34,27,8.5\\n18,36,28,9.0\\n19,38,29,9.5\\n20,40,30,10.0\\n21,42,31,10.5\\n22,44,32,11.0\\n23,46,33,11.5\\n24,48,34,12.0\\n25,50,35,12.5\\n26,52,36,13.0\\n27,54,37,13.5\\n28,56,38,14.0\\n29,58,39,14.5\\n30,60,40,15.0\\n31,62,41,15.5\\n32,64,42,16.0\\n33,66,43,16.5\\n34,68,44,17.0\\n35,70,45,17.5\\n36,72,46,18.0\\n37,74,47,18.5\\n38,76,48,19.0\\n39,78,49,19.5\\n40,80,50,20.0\\n41,82,51,20.5\\n42,84,52,21.0\\n43,86,53,21.5\\n44,88,54,22.0\\n45,90,55,22.5\\n46,92,56,23.0\\n47,94,57,23.5\\n48,96,58,24.0\\n49,98,59,24.5\\n50,100,60,25.0\\n51,102,61,25.5\\n52,104,62,26.0\\n53,106,63,26.5\\n54,108,64,27.0\\n55,110,65,27.5\\n56,112,66,28.0\\n57,114,67,28.5\\n58,116,68,29.0\\n59,118,69,29.5\\n60,120,70,30.0\\n61,122,71,30.5\\n62,124,72,31.0\\n63,126,73,31.5\\n64,128,74,32.0\\n65,130,75,32.5\\n66,132,76,33.0\\n67,134,77,33.5\\n68,136,78,34.0\\n69,138,79,34.5\\n70,140,80,35.0\\n71,142,81,35.5\\n72,144,82,36.0\\n73,146,83,36.5\\n74,148,84,37.0\\n75,150,85,37.5\\n76,152,86,38.0\\n77,154,87,38.5\\n78,156,88,39.0\\n79,158,89,39.5\\n80,160,90,40.0\\n81,162,91,40.5\\n82,164,92,41.0\\n83,166,93,41.5\\n84,168,94,42.0\\n85,170,95,42.5\\n86,172,96,43.0\\n87,174,97,43.5\\n88,176,98,44.0\\n89,178,99,44.5\\n90,180,100,45.0\\n91,182,101,45.5\\n92,184,102,46.0\\n93,186,103,46.5\\n94,188,104,47.0\\n95,190,105,47.5\\n96,192,106,48.0\\n97,194,107,48.5\\n98,196,108,49.0\\n99,198,109,49.5\\n100,200,110,50.0\"\"\"\\n\\n# Load the data into a DataFrame.\\ndf = pd.read_csv(StringIO(csv_data))\\n\\n# 1. Inspect the DataFrame\\nprint(\"First 5 rows of the dataset:\")\\nprint(df.head())\\n\\n# 2. Summary statistics for each column.\\nprint(\"\\\\nSummary Statistics:\")\\nprint(df.describe())\\n\\n# 3. Compute pairwise correlation matrix.\\nprint(\"\\\\nPairwise Correlation Matrix:\")\\nprint(df.corr())\\n\\n# 4. Visualize Pairwise Relationships with seaborn pairplot.\\nsns.pairplot(df)\\nplt.suptitle(\"Pairwise Relationships in the Dataset\", y=1.02)\\nplt.show()\\n\\n# 5. Detailed Scatter Plot and Regression Analysis:\\n# Scatter plot of \\'feature\\' vs. \\'target\\'\\nplt.figure(figsize=(8, 5))\\nsns.scatterplot(data=df, x=\\'feature\\', y=\\'target\\', color=\\'blue\\', s=60, label=\\'Data Points\\')\\n\\n# Fit a linear regression model to predict target from feature.\\nmodel = LinearRegression()\\nX = df[[\\'feature\\']]  # independent variable\\ny = df[\\'target\\']     # dependent variable\\nmodel.fit(X, y)\\n\\n# Retrieve the coefficient and intercept.\\nslope = model.coef_[0]\\nintercept = model.intercept_\\nprint(\"\\\\nLinear Regression Model for Target ~ Feature:\")\\nprint(f\"Slope (Coefficient): {slope}\")\\nprint(f\"Intercept: {intercept}\")\\n\\n# Generate predictions across the range of feature for the regression line.\\nX_range = pd.DataFrame({\\'feature\\': [df[\\'feature\\'].min(), df[\\'feature\\'].max()]})\\ny_pred = model.predict(X_range)\\n\\n# Plot regression line.\\nplt.plot(X_range[\\'feature\\'], y_pred, color=\\'red\\', lw=2, label=f\"Regression Line (y={slope:.2f}x+{intercept:.2f})\")\\nplt.xlabel(\\'Feature\\')\\nplt.ylabel(\\'Target\\')\\nplt.title(\\'Scatter Plot with Regression Line (Feature vs. Target)\\')\\nplt.legend()\\nplt.show()\\n\\n──────────────────────────────\\nExplanation\\n\\n• The code starts by reading the CSV data from the provided multi‐line string.\\n• It prints out the first few rows along with summary statistics using describe().\\n• Next, it computes and prints the correlation matrix to reveal very high correlations among columns (confirming the linear relationships).\\n• A pairplot is generated to visually inspect all pairwise relationships.\\n• A specific scatter plot of “feature” vs. “target” is produced with a red regression line overlaid.\\n• A simple linear regression is performed where we fit “feature” to “target”, and the printed slope and intercept confirm that target ≈ 2 × feature (with slope nearly 2 and an intercept near zero).\\n\\nRunning this code will provide a data-driven confirmation of the underlying linear patterns in the dataset.\\n\\n──────────────────────────────\\nExecution\\n\\nBelow is the execution of the provided Python code. (If running in an interactive environment, the plots will be displayed inline.)\\n\\n[End Code]\\n\\nThis approach is fully data-driven, aligns with the dataset’s structure, and clearly shows that the dataset’s columns are linearly related in the way described.', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)]]\n"
     ]
    }
   ],
   "source": [
    "from app.agents import ToolerOrchestrator\n",
    "from app.schemas import Assembly, Agent\n",
    "\n",
    "def create_sample_assembly() -> Assembly:\n",
    "    \"\"\"\n",
    "    Create a sample assembly with one agent configured for code generation.\n",
    "    The agent (with objective 'code') is expected to generate Python analysis code\n",
    "    that will be executed in a secure Docker container via CodeRunnerPlugin.\n",
    "    \"\"\"\n",
    "\n",
    "    sample_agent = Agent(\n",
    "        id=\"agent1\",\n",
    "        name=\"CodeGenAgent\",\n",
    "        metaprompt=(\n",
    "            \"You are a Python code generation agent. Generate code that loads a CSV file, \"\n",
    "            \"which is mounted as 'uploaded_file.csv', and prints its first five rows. \"\n",
    "            \"Do not include any additional commentary – just produce valid Python code.\"\n",
    "        ),\n",
    "        model_id=\"default\",\n",
    "        objective=\"code\"\n",
    "    )\n",
    "\n",
    "    return Assembly(\n",
    "        id=\"sample_assembly\",\n",
    "        agents=[sample_agent],\n",
    "        objective=\"CSV Analysis Code Generation\",\n",
    "        roles=[\"code_generator\"],\n",
    "    )\n",
    "\n",
    "async def main():\n",
    "    # Create the sample assembly that defines our agent(s).\n",
    "    assembly = create_sample_assembly()\n",
    "    prompt = \"\"\"\n",
    "feature,target,col3,col4\n",
    "1,2,11,0.5\n",
    "2,4,12,1.0\n",
    "3,6,13,1.5\n",
    "4,8,14,2.0\n",
    "5,10,15,2.5\n",
    "6,12,16,3.0\n",
    "7,14,17,3.5\n",
    "8,16,18,4.0\n",
    "9,18,19,4.5\n",
    "10,20,20,5.0\n",
    "11,22,21,5.5\n",
    "12,24,22,6.0\n",
    "13,26,23,6.5\n",
    "14,28,24,7.0\n",
    "15,30,25,7.5\n",
    "16,32,26,8.0\n",
    "17,34,27,8.5\n",
    "18,36,28,9.0\n",
    "19,38,29,9.5\n",
    "20,40,30,10.0\n",
    "21,42,31,10.5\n",
    "22,44,32,11.0\n",
    "23,46,33,11.5\n",
    "24,48,34,12.0\n",
    "25,50,35,12.5\n",
    "26,52,36,13.0\n",
    "27,54,37,13.5\n",
    "28,56,38,14.0\n",
    "29,58,39,14.5\n",
    "30,60,40,15.0\n",
    "31,62,41,15.5\n",
    "32,64,42,16.0\n",
    "33,66,43,16.5\n",
    "34,68,44,17.0\n",
    "35,70,45,17.5\n",
    "36,72,46,18.0\n",
    "37,74,47,18.5\n",
    "38,76,48,19.0\n",
    "39,78,49,19.5\n",
    "40,80,50,20.0\n",
    "41,82,51,20.5\n",
    "42,84,52,21.0\n",
    "43,86,53,21.5\n",
    "44,88,54,22.0\n",
    "45,90,55,22.5\n",
    "46,92,56,23.0\n",
    "47,94,57,23.5\n",
    "48,96,58,24.0\n",
    "49,98,59,24.5\n",
    "50,100,60,25.0\n",
    "51,102,61,25.5\n",
    "52,104,62,26.0\n",
    "53,106,63,26.5\n",
    "54,108,64,27.0\n",
    "55,110,65,27.5\n",
    "56,112,66,28.0\n",
    "57,114,67,28.5\n",
    "58,116,68,29.0\n",
    "59,118,69,29.5\n",
    "60,120,70,30.0\n",
    "61,122,71,30.5\n",
    "62,124,72,31.0\n",
    "63,126,73,31.5\n",
    "64,128,74,32.0\n",
    "65,130,75,32.5\n",
    "66,132,76,33.0\n",
    "67,134,77,33.5\n",
    "68,136,78,34.0\n",
    "69,138,79,34.5\n",
    "70,140,80,35.0\n",
    "71,142,81,35.5\n",
    "72,144,82,36.0\n",
    "73,146,83,36.5\n",
    "74,148,84,37.0\n",
    "75,150,85,37.5\n",
    "76,152,86,38.0\n",
    "77,154,87,38.5\n",
    "78,156,88,39.0\n",
    "79,158,89,39.5\n",
    "80,160,90,40.0\n",
    "81,162,91,40.5\n",
    "82,164,92,41.0\n",
    "83,166,93,41.5\n",
    "84,168,94,42.0\n",
    "85,170,95,42.5\n",
    "86,172,96,43.0\n",
    "87,174,97,43.5\n",
    "88,176,98,44.0\n",
    "89,178,99,44.5\n",
    "90,180,100,45.0\n",
    "91,182,101,45.5\n",
    "92,184,102,46.0\n",
    "93,186,103,46.5\n",
    "94,188,104,47.0\n",
    "95,190,105,47.5\n",
    "96,192,106,48.0\n",
    "97,194,107,48.5\n",
    "98,196,108,49.0\n",
    "99,198,109,49.5\n",
    "100,200,110,50.0\n",
    "\"\"\"\n",
    "    orchestrator = ToolerOrchestrator()\n",
    "    print(\"Aggregated Responses:\")\n",
    "    response = await orchestrator.run_interaction(assembly, prompt, strategy=\"llm\")\n",
    "    print(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
